{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NataliaLak/AllTasks/blob/main/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%D0%98%D0%BD%D1%84%D1%80%D0%B0%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D0%B0_%D0%B4%D0%BB%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B5%D0%B8%CC%86_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Инфраструктура для моделей машинного обучения. Практическая работа\n",
        "\n",
        "# Цель практической работы\n",
        "\n",
        "Потренироваться в использовании библиотек PySpark SQL и PySpark ML для предобработки данных и обучения моделей.\n",
        "\n",
        "# Что входит в практическую работу\n",
        "\n",
        "1. Инициализация спарк-сессии.\n",
        "2. Загрузка данных.\n",
        "3. Ознакомление с данными.\n",
        "4. Преобразование типов столбцов.\n",
        "5. Очистка данных.\n",
        "6. Feature-инжиниринг.\n",
        "7. Векторизация фичей.\n",
        "8. Создание и обучение модели.\n",
        "9. Выбор лучшей модели.\n",
        "10. Обратная связь.\n",
        "\n",
        "\n",
        "# Что оценивается\n",
        "\n",
        "- Пройдены все этапы работы.\n",
        "- Спарк-сессия успешно запущена.\n",
        "- Данные прочитаны.\n",
        "- Все колонки с числовыми значениями преобразованы в числовые типы данных (Int или Double).\n",
        "- Отфильтрованы все строки с Null-значениями.\n",
        "- Созданы новые фичи.\n",
        "- Все категориальные колонки преобразованы в числовой вид, выполнены все этапы векторизации признаков.\n",
        "- Выборка разделена на обучающую и тестовую.\n",
        "- Создано три объекта: модель, сетка гиперпараметров и evaluator.\n",
        "- Создан объект класса CrossValidator и обучен на обучающей выборке.\n",
        "- Выбрана лучшая модель, посчитана метрика качества лучшей модели.\n",
        "\n",
        "\n",
        "# Задача\n",
        "\n",
        "Используя данные о клиентах телекоммуникационной компании, обучите модель, предсказывающую их отток.\n",
        "\n",
        "Описание данных, с которыми вы будете работать:\n",
        "\n",
        "* **CustomerID**: ID клиента.\n",
        "* **Gender**: пол клиента.\n",
        "* **SeniorCitizen**: пенсионер ли клиент (1 — да, 0 — нет).\n",
        "* **Partner**: есть у клиента партнёр (жена, муж) или нет (Yes/No).\n",
        "* **Dependents**: есть ли у клиента инждивенцы, например дети (Yes/No).\n",
        "* **Tenure**: как много месяцев клиент оставался в компании.\n",
        "* **PhoneService**: подключена ли у клиента телефонная служба (Yes/No).\n",
        "* **MultipleLines**: подключено ли несколько телефонных линий (Yes, No, No phone service).\n",
        "* **InternetService**: интернет-провайдер клиента (DSL, Fiber optic, No).\n",
        "* **OnlineSecurity**: подключена ли у клиента услуга онлайн-безопасности (Yes, No, No internet service)\n",
        "* **OnlineBackup**: подключена ли услуга резервного копирования онлайн (Yes, No, No internet service).\n",
        "* **DeviceProtection**: подключена ли услуга защиты устройства (Yes, No, No internet service)\n",
        "* **TechSupport**: есть ли у клиента техническая поддержка (Yes, No, No internet service).\n",
        "* **StreamingTV**: подключена ли услуга потокового телевидения (Yes, No, No internet service).\n",
        "* **StreamingMovies**: подключена ли услуга стримингового воспроизведения фильмов (Yes, No, No internet service).\n",
        "* **Contract**: тип контракта клиента (Month-to-month, One year, Two year).\n",
        "* **PaperlessBilling**: есть ли безбумажный счёт.\n",
        "* **PaymentMethod**: способ оплаты услуг (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic)).\n",
        "* **MonthlyCharges**: сумма, которая списывается ежемесячно.\n",
        "* **TotalCharges**: сумма, списанная за всё время.\n",
        "* **Churn**: ушёл ли клиент (Yes/No). Это целевая переменная, которую нужно предсказать.\n"
      ],
      "metadata": {
        "id": "p92rzC-2D71g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Инициализация спарк-сессии"
      ],
      "metadata": {
        "id": "CZmr6VeYvLKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализируйте спарк-сессию.\n",
        "\n",
        "Эта ячейка нужна для того, чтобы заргузить необходимые библиотеки и настроить окружение Google Colab для работы со Spark.\n",
        "\n",
        "Просто запустите её перед выполением задания :)"
      ],
      "metadata": {
        "id": "EO2v2cOjyZBN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UuUc1cxHuymb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e6ca2f-c9ab-4ab2-80eb-2a7979698719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark --quiet\n",
        "!pip install -U -q PyDrive --quiet\n",
        "!apt install openjdk-8-jdk-headless &> /dev/null\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip &> /dev/null\n",
        "!unzip ngrok-stable-linux-amd64.zip &> /dev/null\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local[*]\")\\\n",
        "        .appName('PySpark_Tutorial')\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "8Q743I78vA5_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Загрузка данных\n",
        "Загрузите данные, сохраните их в переменную типа sparkDataframe, используя метод read.csv (не забывайте про header и delimiter)."
      ],
      "metadata": {
        "id": "e55O3aB5vo3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.read.option(\"header\",True).option(\"delimiter\", \",\").csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")"
      ],
      "metadata": {
        "id": "1GVOybUCvlXy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Ознакомление с данными\n",
        "1. Выведите на экран первые несколько строк датафрейма.\n"
      ],
      "metadata": {
        "id": "k8amaWNGzDsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.show(5)"
      ],
      "metadata": {
        "id": "bPfkFFUoz19Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "712d2a4f-4edc-4557-fde0-ad13979aed1e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|   MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "|7590-VHVEG|Female|            0|    Yes|        No|     1|          No|No phone service|            DSL|            No|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|         29.85|       29.85|   No|\n",
            "|5575-GNVDE|  Male|            0|     No|        No|    34|         Yes|              No|            DSL|           Yes|          No|             Yes|         No|         No|             No|      One year|              No|        Mailed check|         56.95|      1889.5|   No|\n",
            "|3668-QPYBK|  Male|            0|     No|        No|     2|         Yes|              No|            DSL|           Yes|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|        Mailed check|         53.85|      108.15|  Yes|\n",
            "|7795-CFOCW|  Male|            0|     No|        No|    45|          No|No phone service|            DSL|           Yes|          No|             Yes|        Yes|         No|             No|      One year|              No|Bank transfer (au...|          42.3|     1840.75|   No|\n",
            "|9237-HQITU|Female|            0|     No|        No|     2|         Yes|              No|    Fiber optic|            No|          No|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|          70.7|      151.65|  Yes|\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. Выведите общее количество строк датафрейма.\n",
        "\n"
      ],
      "metadata": {
        "id": "vMgX25wr0JfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.count()"
      ],
      "metadata": {
        "id": "ivgw172qz9o_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e194825-2392-4f4d-ce09-d3095f26907a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7043"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Выведите структуру (схему) датафрейма."
      ],
      "metadata": {
        "id": "xCAeIZFe0KyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.printSchema()"
      ],
      "metadata": {
        "id": "KmZY25zX0Fd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a635ab42-aae8-40e8-cbe6-735c68014ac2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- customerID: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- SeniorCitizen: string (nullable = true)\n",
            " |-- Partner: string (nullable = true)\n",
            " |-- Dependents: string (nullable = true)\n",
            " |-- tenure: string (nullable = true)\n",
            " |-- PhoneService: string (nullable = true)\n",
            " |-- MultipleLines: string (nullable = true)\n",
            " |-- InternetService: string (nullable = true)\n",
            " |-- OnlineSecurity: string (nullable = true)\n",
            " |-- OnlineBackup: string (nullable = true)\n",
            " |-- DeviceProtection: string (nullable = true)\n",
            " |-- TechSupport: string (nullable = true)\n",
            " |-- StreamingTV: string (nullable = true)\n",
            " |-- StreamingMovies: string (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- PaperlessBilling: string (nullable = true)\n",
            " |-- PaymentMethod: string (nullable = true)\n",
            " |-- MonthlyCharges: string (nullable = true)\n",
            " |-- TotalCharges: string (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Преобразование типов столбцов\n",
        "Преобразуйте тип столбцов у числовых признаков (Int — если признак целочисленный, Double — если признак не целочисленный). Сохраните преобразованный датафрейм в новую переменную.\n",
        "\n",
        "## Совет\n",
        "\n",
        "Если вам сложно выполнить это задание, изучите дополнительные материалы: [об операторе Cast](https://sparkbyexamples.com/pyspark/pyspark-cast-column-type/), [об операторе Select](https://sparkbyexamples.com/pyspark/select-columns-from-pyspark-dataframe/).\n",
        "\n"
      ],
      "metadata": {
        "id": "DFcKPAI_0cF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr, col\n",
        "\n",
        "data1 = data.select(\n",
        "    col(\"customerID\"),\n",
        "    col(\"gender\"),\n",
        "    col(\"SeniorCitizen\").cast(\"int\"),\n",
        "    col(\"Partner\"),\n",
        "    col(\"Dependents\"),\n",
        "    col(\"tenure\").cast(\"int\"),\n",
        "    col(\"PhoneService\"),\n",
        "    col(\"MultipleLines\"),\n",
        "    col(\"InternetService\"),\n",
        "    col(\"OnlineSecurity\"),\n",
        "    col(\"OnlineBackup\"),\n",
        "    col(\"DeviceProtection\"),\n",
        "    col(\"TechSupport\"),\n",
        "    col(\"StreamingTV\"),\n",
        "    col(\"StreamingMovies\"),\n",
        "    col(\"Contract\"),\n",
        "    col(\"PaperlessBilling\"),\n",
        "    col(\"PaymentMethod\"),\n",
        "    col(\"MonthlyCharges\").cast(\"double\"),\n",
        "    col(\"TotalCharges\").cast(\"double\"),\n",
        "    col(\"Churn\")\n",
        ")\n",
        "\n",
        "# Выводим схему для проверки\n",
        "data1.printSchema()"
      ],
      "metadata": {
        "id": "Kihtrqni0-Js",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d546359c-763c-4bc1-8a08-ee32ee46df66"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- customerID: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- SeniorCitizen: integer (nullable = true)\n",
            " |-- Partner: string (nullable = true)\n",
            " |-- Dependents: string (nullable = true)\n",
            " |-- tenure: integer (nullable = true)\n",
            " |-- PhoneService: string (nullable = true)\n",
            " |-- MultipleLines: string (nullable = true)\n",
            " |-- InternetService: string (nullable = true)\n",
            " |-- OnlineSecurity: string (nullable = true)\n",
            " |-- OnlineBackup: string (nullable = true)\n",
            " |-- DeviceProtection: string (nullable = true)\n",
            " |-- TechSupport: string (nullable = true)\n",
            " |-- StreamingTV: string (nullable = true)\n",
            " |-- StreamingMovies: string (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- PaperlessBilling: string (nullable = true)\n",
            " |-- PaymentMethod: string (nullable = true)\n",
            " |-- MonthlyCharges: double (nullable = true)\n",
            " |-- TotalCharges: double (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Очистка данных\n",
        "Проверьте, есть ли в какой-либо колонке Null-значения. Для этого можно использовать your_dataframe.filter(col(\"colname\")).isNull()).\n",
        "\n",
        "Выведите на экран несколько строк с Null-значениями в одной из колонок.\n",
        "\n",
        "Сохраните очищенный от строк с Null-значениями датафрейм в новую переменную. Для фильтрации этих значений можно использовать метод .isNotNull().\n",
        "\n",
        "Колонок в датафрейме много, проверять каждую неудобно и долго. Подумайте, как упроситить эту работу, если использовать, например, перебор с циклом for.\n",
        "\n",
        "[Примеры использования операторов isNull() и isNotNull()](https://sparkbyexamples.com/pyspark/pyspark-isnull/).\n"
      ],
      "metadata": {
        "id": "1hBBiIm350BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_columns = {}\n",
        "for column in data1.columns:\n",
        "    null_count = data1.filter(col(column).isNull()).count()\n",
        "    if null_count > 0:\n",
        "        null_columns[column] = null_count\n",
        "\n",
        "# Вывод колонок с Null-значениями и их количества\n",
        "print(\"Колонки с Null-значениями и их количество:\")\n",
        "for column, count in null_columns.items():\n",
        "    print(f\"{column}: {count}\")\n"
      ],
      "metadata": {
        "id": "A0FTVvpg6_iy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82e340d-45f3-461a-958a-c9d595b05e44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Колонки с Null-значениями и их количество:\n",
            "TotalCharges: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhs9R6KmavZf",
        "outputId": "beed2679-fdbb-417c-99f6-2fbd50c08435"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7043"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = data1.dropna()"
      ],
      "metadata": {
        "id": "hfiD04RSa0Wv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVtBfAJwa9PP",
        "outputId": "54be411d-652f-4b62-f4c7-9602d244cb1e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7032"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Feature-инжиниринг\n",
        "Добавьте в датафрейм одну или несколько новых фичей. Удалите колонки, которые, как вам кажется, нужно убрать из фичей. Обоснуйте свои решения."
      ],
      "metadata": {
        "id": "fMRcAbphNBEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Колонка customerID является уникальным идентификатором для каждого клиента и не несет полезной информации для модели предсказания оттока клиентов."
      ],
      "metadata": {
        "id": "tv9V5z4ablp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "data2 = data2.drop(\"customerID\")"
      ],
      "metadata": {
        "id": "6SZ_rocx79oY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавляем фичу TotalChargesPerTenure, которая будет показывать среднюю ежемесячную стоимость для клиента за весь период."
      ],
      "metadata": {
        "id": "-o_gx5AQbuhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = data2.withColumn(\n",
        "    \"TotalChargesPerTenure\",\n",
        "    when(col(\"tenure\") != 0, col(\"TotalCharges\") / col(\"tenure\")).otherwise(0)\n",
        ")"
      ],
      "metadata": {
        "id": "W05k-zT5cKVR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2.printSchema()\n",
        "data2.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DybCgoi9cTSW",
        "outputId": "b9cf488f-75f0-491e-fa5e-e1f69cde0503"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- gender: string (nullable = true)\n",
            " |-- SeniorCitizen: integer (nullable = true)\n",
            " |-- Partner: string (nullable = true)\n",
            " |-- Dependents: string (nullable = true)\n",
            " |-- tenure: integer (nullable = true)\n",
            " |-- PhoneService: string (nullable = true)\n",
            " |-- MultipleLines: string (nullable = true)\n",
            " |-- InternetService: string (nullable = true)\n",
            " |-- OnlineSecurity: string (nullable = true)\n",
            " |-- OnlineBackup: string (nullable = true)\n",
            " |-- DeviceProtection: string (nullable = true)\n",
            " |-- TechSupport: string (nullable = true)\n",
            " |-- StreamingTV: string (nullable = true)\n",
            " |-- StreamingMovies: string (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- PaperlessBilling: string (nullable = true)\n",
            " |-- PaymentMethod: string (nullable = true)\n",
            " |-- MonthlyCharges: double (nullable = true)\n",
            " |-- TotalCharges: double (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            " |-- TotalChargesPerTenure: double (nullable = true)\n",
            "\n",
            "+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+---------------------+\n",
            "|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|   MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|MonthlyCharges|TotalCharges|Churn|TotalChargesPerTenure|\n",
            "+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+---------------------+\n",
            "|Female|            0|    Yes|        No|     1|          No|No phone service|            DSL|            No|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|         29.85|       29.85|   No|                29.85|\n",
            "|  Male|            0|     No|        No|    34|         Yes|              No|            DSL|           Yes|          No|             Yes|         No|         No|             No|      One year|              No|        Mailed check|         56.95|      1889.5|   No|     55.5735294117647|\n",
            "|  Male|            0|     No|        No|     2|         Yes|              No|            DSL|           Yes|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|        Mailed check|         53.85|      108.15|  Yes|               54.075|\n",
            "|  Male|            0|     No|        No|    45|          No|No phone service|            DSL|           Yes|          No|             Yes|        Yes|         No|             No|      One year|              No|Bank transfer (au...|          42.3|     1840.75|   No|    40.90555555555556|\n",
            "|Female|            0|     No|        No|     2|         Yes|              No|    Fiber optic|            No|          No|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|          70.7|      151.65|  Yes|               75.825|\n",
            "+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+---------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Векторизация фичей\n",
        "Подготовьте данные к обучению:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mX-4GEdHTZWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Преобразуйте текстовые колонки в числа, используя StringIndexer.\n",
        "Удалите столбцы со старыми (непреобразованными) признаками. Выведите на экран структуру получившегося датафрейма. Не забывайте о столбце Churn. Хоть он и выступает в задаче как таргет, он имеет текстовый тип, поэтому тоже должен быть закодирован числовыми значениями.\n",
        "\n",
        "Чтобы использовать StringIndexer для всех категориальных признаков сразу, а не для каждого отдельно, можно применить сущность pipeline.\n",
        "\n",
        "**Пример кода:**\n",
        "\n",
        "##### #Задаём список текстовых колонок:\n",
        "text_columns = [\"text_col_1\", \"text_col_2\", \"text_col_3\"]\n",
        "\n",
        "##### #Задаём список StringIndexer'ов — сущностей, каждая из которых будет кодировать одну текстовую колонку числами. Имена преобразованных колонок будут заканчиваться на _index:\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\",).fit(<ваш датасет>) for column in text_columns]\n",
        "\n",
        "##### #Создаём Pipeline из StringIndexer'ов:\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "\n",
        "##### #Скармливаем нашему pipeline датафрейм, удаляя старые колонки:\n",
        "new_dataframe = pipeline.fit(<ваш датасет>).transform(<ваш датасет>).drop(*text_columns)\n"
      ],
      "metadata": {
        "id": "x5cNxN2qq3SL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import mllib\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "#список колонок с текстовым типом\n",
        "text_cols = [\"gender\", \"Partner\", \"Dependents\", \"PhoneService\", \"MultipleLines\", \"InternetService\", \\\n",
        "                \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \\\n",
        "                \"StreamingMovies\", \"Contract\", \"PaperlessBilling\", \"PaymentMethod\", \"Churn\"]\n",
        "\n",
        "\n",
        "# Создание списка StringIndexer'ов для каждой текстовой колонки\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\").fit(data2) for column in text_cols]\n",
        "\n",
        "# Создание Pipeline\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "\n",
        "# Применение Pipeline к датафрейму и удаление старых колонок\n",
        "data_indexed = pipeline.fit(data2).transform(data2).drop(*text_cols)\n",
        "\n",
        "# Вывод структуры получившегося датафрейма\n",
        "data_indexed.printSchema()\n",
        "data_indexed.show(5)"
      ],
      "metadata": {
        "id": "0XQ3pjdAcBIL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a5ab27-6e30-4ffc-9271-243064bf3518"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- SeniorCitizen: integer (nullable = true)\n",
            " |-- tenure: integer (nullable = true)\n",
            " |-- MonthlyCharges: double (nullable = true)\n",
            " |-- TotalCharges: double (nullable = true)\n",
            " |-- TotalChargesPerTenure: double (nullable = true)\n",
            " |-- gender_index: double (nullable = false)\n",
            " |-- Partner_index: double (nullable = false)\n",
            " |-- Dependents_index: double (nullable = false)\n",
            " |-- PhoneService_index: double (nullable = false)\n",
            " |-- MultipleLines_index: double (nullable = false)\n",
            " |-- InternetService_index: double (nullable = false)\n",
            " |-- OnlineSecurity_index: double (nullable = false)\n",
            " |-- OnlineBackup_index: double (nullable = false)\n",
            " |-- DeviceProtection_index: double (nullable = false)\n",
            " |-- TechSupport_index: double (nullable = false)\n",
            " |-- StreamingTV_index: double (nullable = false)\n",
            " |-- StreamingMovies_index: double (nullable = false)\n",
            " |-- Contract_index: double (nullable = false)\n",
            " |-- PaperlessBilling_index: double (nullable = false)\n",
            " |-- PaymentMethod_index: double (nullable = false)\n",
            " |-- Churn_index: double (nullable = false)\n",
            "\n",
            "+-------------+------+--------------+------------+---------------------+------------+-------------+----------------+------------------+-------------------+---------------------+--------------------+------------------+----------------------+-----------------+-----------------+---------------------+--------------+----------------------+-------------------+-----------+\n",
            "|SeniorCitizen|tenure|MonthlyCharges|TotalCharges|TotalChargesPerTenure|gender_index|Partner_index|Dependents_index|PhoneService_index|MultipleLines_index|InternetService_index|OnlineSecurity_index|OnlineBackup_index|DeviceProtection_index|TechSupport_index|StreamingTV_index|StreamingMovies_index|Contract_index|PaperlessBilling_index|PaymentMethod_index|Churn_index|\n",
            "+-------------+------+--------------+------------+---------------------+------------+-------------+----------------+------------------+-------------------+---------------------+--------------------+------------------+----------------------+-----------------+-----------------+---------------------+--------------+----------------------+-------------------+-----------+\n",
            "|            0|     1|         29.85|       29.85|                29.85|         1.0|          1.0|             0.0|               1.0|                2.0|                  1.0|                 0.0|               1.0|                   0.0|              0.0|              0.0|                  0.0|           0.0|                   0.0|                0.0|        0.0|\n",
            "|            0|    34|         56.95|      1889.5|     55.5735294117647|         0.0|          0.0|             0.0|               0.0|                0.0|                  1.0|                 1.0|               0.0|                   1.0|              0.0|              0.0|                  0.0|           2.0|                   1.0|                1.0|        0.0|\n",
            "|            0|     2|         53.85|      108.15|               54.075|         0.0|          0.0|             0.0|               0.0|                0.0|                  1.0|                 1.0|               1.0|                   0.0|              0.0|              0.0|                  0.0|           0.0|                   0.0|                1.0|        1.0|\n",
            "|            0|    45|          42.3|     1840.75|    40.90555555555556|         0.0|          0.0|             0.0|               1.0|                2.0|                  1.0|                 1.0|               0.0|                   1.0|              1.0|              0.0|                  0.0|           2.0|                   1.0|                2.0|        0.0|\n",
            "|            0|     2|          70.7|      151.65|               75.825|         1.0|          0.0|             0.0|               0.0|                0.0|                  0.0|                 0.0|               0.0|                   0.0|              0.0|              0.0|                  0.0|           0.0|                   0.0|                0.0|        1.0|\n",
            "+-------------+------+--------------+------------+---------------------+------------+-------------+----------------+------------------+-------------------+---------------------+--------------------+------------------+----------------------+-----------------+-----------------+---------------------+--------------+----------------------+-------------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Векторизуйте категориальные признаки, используя OneHotEncoder.\n",
        "Удалите столбцы со старыми (непреобразованными) признаками.\n",
        "Выведите на экран структуру получившегося после преобразований датафрейма.\n"
      ],
      "metadata": {
        "id": "EEqoj7IcmB5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import OneHotEncoder\n",
        "\n",
        "#список категориальных колонок\n",
        "features_inp  = [\"gender_index\", \"Partner_index\", \"Dependents_index\", \"PhoneService_index\", \"MultipleLines_index\",\n",
        "                \"InternetService_index\", \"OnlineSecurity_index\", \"OnlineBackup_index\", \"DeviceProtection_index\",\n",
        "                \"TechSupport_index\", \"StreamingTV_index\", \"StreamingMovies_index\", \"Contract_index\",\n",
        "                \"PaperlessBilling_index\", \"PaymentMethod_index\"]\n",
        "\n",
        "\n",
        "encoders = [OneHotEncoder(inputCol=column, outputCol=column + \"_vec\") for column in features_inp]\n",
        "\n",
        "# Создание Pipeline для OneHotEncoder\n",
        "pipeline = Pipeline(stages=encoders)\n",
        "\n",
        "# Применение Pipeline к датафрейму и удаление старых индексированных колонок\n",
        "data_encoded = pipeline.fit(data_indexed).transform(data_indexed).drop(*features_inp)\n",
        "\n",
        "# Вывод структуры получившегося датафрейма\n",
        "data_encoded.printSchema()\n",
        "data_encoded.show(5)"
      ],
      "metadata": {
        "id": "Gihv_Q00TkOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa5354e-36e0-4a7f-bc27-b96ac38ce6a1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- SeniorCitizen: integer (nullable = true)\n",
            " |-- tenure: integer (nullable = true)\n",
            " |-- MonthlyCharges: double (nullable = true)\n",
            " |-- TotalCharges: double (nullable = true)\n",
            " |-- TotalChargesPerTenure: double (nullable = true)\n",
            " |-- Churn_index: double (nullable = false)\n",
            " |-- gender_index_vec: vector (nullable = true)\n",
            " |-- Partner_index_vec: vector (nullable = true)\n",
            " |-- Dependents_index_vec: vector (nullable = true)\n",
            " |-- PhoneService_index_vec: vector (nullable = true)\n",
            " |-- MultipleLines_index_vec: vector (nullable = true)\n",
            " |-- InternetService_index_vec: vector (nullable = true)\n",
            " |-- OnlineSecurity_index_vec: vector (nullable = true)\n",
            " |-- OnlineBackup_index_vec: vector (nullable = true)\n",
            " |-- DeviceProtection_index_vec: vector (nullable = true)\n",
            " |-- TechSupport_index_vec: vector (nullable = true)\n",
            " |-- StreamingTV_index_vec: vector (nullable = true)\n",
            " |-- StreamingMovies_index_vec: vector (nullable = true)\n",
            " |-- Contract_index_vec: vector (nullable = true)\n",
            " |-- PaperlessBilling_index_vec: vector (nullable = true)\n",
            " |-- PaymentMethod_index_vec: vector (nullable = true)\n",
            "\n",
            "+-------------+------+--------------+------------+---------------------+-----------+----------------+-----------------+--------------------+----------------------+-----------------------+-------------------------+------------------------+----------------------+--------------------------+---------------------+---------------------+-------------------------+------------------+--------------------------+-----------------------+\n",
            "|SeniorCitizen|tenure|MonthlyCharges|TotalCharges|TotalChargesPerTenure|Churn_index|gender_index_vec|Partner_index_vec|Dependents_index_vec|PhoneService_index_vec|MultipleLines_index_vec|InternetService_index_vec|OnlineSecurity_index_vec|OnlineBackup_index_vec|DeviceProtection_index_vec|TechSupport_index_vec|StreamingTV_index_vec|StreamingMovies_index_vec|Contract_index_vec|PaperlessBilling_index_vec|PaymentMethod_index_vec|\n",
            "+-------------+------+--------------+------------+---------------------+-----------+----------------+-----------------+--------------------+----------------------+-----------------------+-------------------------+------------------------+----------------------+--------------------------+---------------------+---------------------+-------------------------+------------------+--------------------------+-----------------------+\n",
            "|            0|     1|         29.85|       29.85|                29.85|        0.0|       (1,[],[])|        (1,[],[])|       (1,[0],[1.0])|             (1,[],[])|              (2,[],[])|            (2,[1],[1.0])|           (2,[0],[1.0])|         (2,[1],[1.0])|             (2,[0],[1.0])|        (2,[0],[1.0])|        (2,[0],[1.0])|            (2,[0],[1.0])|     (2,[0],[1.0])|             (1,[0],[1.0])|          (3,[0],[1.0])|\n",
            "|            0|    34|         56.95|      1889.5|     55.5735294117647|        0.0|   (1,[0],[1.0])|    (1,[0],[1.0])|       (1,[0],[1.0])|         (1,[0],[1.0])|          (2,[0],[1.0])|            (2,[1],[1.0])|           (2,[1],[1.0])|         (2,[0],[1.0])|             (2,[1],[1.0])|        (2,[0],[1.0])|        (2,[0],[1.0])|            (2,[0],[1.0])|         (2,[],[])|                 (1,[],[])|          (3,[1],[1.0])|\n",
            "|            0|     2|         53.85|      108.15|               54.075|        1.0|   (1,[0],[1.0])|    (1,[0],[1.0])|       (1,[0],[1.0])|         (1,[0],[1.0])|          (2,[0],[1.0])|            (2,[1],[1.0])|           (2,[1],[1.0])|         (2,[1],[1.0])|             (2,[0],[1.0])|        (2,[0],[1.0])|        (2,[0],[1.0])|            (2,[0],[1.0])|     (2,[0],[1.0])|             (1,[0],[1.0])|          (3,[1],[1.0])|\n",
            "|            0|    45|          42.3|     1840.75|    40.90555555555556|        0.0|   (1,[0],[1.0])|    (1,[0],[1.0])|       (1,[0],[1.0])|             (1,[],[])|              (2,[],[])|            (2,[1],[1.0])|           (2,[1],[1.0])|         (2,[0],[1.0])|             (2,[1],[1.0])|        (2,[1],[1.0])|        (2,[0],[1.0])|            (2,[0],[1.0])|         (2,[],[])|                 (1,[],[])|          (3,[2],[1.0])|\n",
            "|            0|     2|          70.7|      151.65|               75.825|        1.0|       (1,[],[])|    (1,[0],[1.0])|       (1,[0],[1.0])|         (1,[0],[1.0])|          (2,[0],[1.0])|            (2,[0],[1.0])|           (2,[0],[1.0])|         (2,[0],[1.0])|             (2,[0],[1.0])|        (2,[0],[1.0])|        (2,[0],[1.0])|            (2,[0],[1.0])|     (2,[0],[1.0])|             (1,[0],[1.0])|          (3,[0],[1.0])|\n",
            "+-------------+------+--------------+------------+---------------------+-----------+----------------+-----------------+--------------------+----------------------+-----------------------+-------------------------+------------------------+----------------------+--------------------------+---------------------+---------------------+-------------------------+------------------+--------------------------+-----------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Объедините колонки фичей в один вектор, используя VectorAssembler.\n",
        "Удалите столбцы со старыми (непреобразованными) признаками.\n",
        "Выведите на экран первые несколько строк и структуру получившегося датафрейма."
      ],
      "metadata": {
        "id": "WscurK1IoJ8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "\n",
        "feature_columns = [\"SeniorCitizen\", \"tenure\", \"MonthlyCharges\", \"TotalCharges\", \"TotalChargesPerTenure\"] + \\\n",
        "                  [column + \"_vec\" for column in features_inp]\n",
        "\n",
        "# Создание VectorAssembler для объединения всех фичей в один вектор\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "# Применение VectorAssembler к датафрейму\n",
        "data_final = assembler.transform(data_encoded).select(\"features\", \"Churn_index\")\n",
        "\n",
        "# Вывод структуры получившегося датафрейма\n",
        "data_final.printSchema()\n",
        "data_final.show(5)"
      ],
      "metadata": {
        "id": "wOm-Te9bYMia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b742d3-5446-4af2-b79e-fca5013bac4c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- features: vector (nullable = true)\n",
            " |-- Churn_index: double (nullable = false)\n",
            "\n",
            "+--------------------+-----------+\n",
            "|            features|Churn_index|\n",
            "+--------------------+-----------+\n",
            "|(31,[1,2,3,4,7,12...|        0.0|\n",
            "|(31,[1,2,3,4,5,6,...|        0.0|\n",
            "|(31,[1,2,3,4,5,6,...|        1.0|\n",
            "|(31,[1,2,3,4,5,6,...|        0.0|\n",
            "|(31,[1,2,3,4,6,7,...|        1.0|\n",
            "+--------------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка пропущенных значений в столбце 'features'\n",
        "null_features_count = data_final.filter(col(\"features\").isNull()).count()\n",
        "\n",
        "# Проверка пропущенных значений в столбце 'Churn_index'\n",
        "null_churn_index_count = data_final.filter(col(\"Churn_index\").isNull()).count()\n",
        "\n",
        "print(f\"Количество строк с пропущенными значениями в 'features': {null_features_count}\")\n",
        "print(f\"Количество строк с пропущенными значениями в 'Churn_index': {null_churn_index_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUX8D3JdkU3F",
        "outputId": "f0ac3d42-0423-4f54-cecd-6728f219162d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество строк с пропущенными значениями в 'features': 0\n",
            "Количество строк с пропущенными значениями в 'Churn_index': 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Создание и обучение модели"
      ],
      "metadata": {
        "id": "uk_1ZJjDqm02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Создайте модель — логистическую регрессию (используя LogisticRegression). В качестве параметров класса LogisticRegression укажите колонку фичей (параметр featuresCol), колонку-таргет (параметр labelCol) из датафрейма и имя колонки, в которую будут записываться предсказания (параметр predictionCol)."
      ],
      "metadata": {
        "id": "fMsi-JYVqvkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "logistic_regression = LogisticRegression(\n",
        "    featuresCol=\"features\",  # Колонка с фичами\n",
        "    labelCol=\"Churn_index\",  # Колонка с целевой переменной\n",
        "    predictionCol=\"prediction\"  # Колонка для хранения предсказаний\n",
        ")"
      ],
      "metadata": {
        "id": "siYFALNhq_9F"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Разделите датафрейм на обучающую и тестовую выборку."
      ],
      "metadata": {
        "id": "OCG0euR8v33u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = data_final.randomSplit([0.8, 0.2], seed=1234)"
      ],
      "metadata": {
        "id": "g9PoHvGqvvET"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Создайте объекты — сетки гиперпараметров для каждой модели, используя ParamGridBuilder. Так же, как и в ноутбуке из последнего видео, в сетку гиперпараметров можно добавить значения параметров regParam и elasticNetParam.\n",
        "\n",
        "Вы можете ознакомиться [с документацией объекта LogisticRegression в PySpark](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.LogisticRegression.html) и добавить в сетку больше параметров.\n"
      ],
      "metadata": {
        "id": "MyGEK9T_wGWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "\n",
        "grid = ParamGridBuilder().addGrid(logistic_regression.regParam, [0.5, 5]).addGrid(logistic_regression.elasticNetParam, [0.01, 0.1]).build()"
      ],
      "metadata": {
        "id": "LsRwAy1TwDzF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Создайте объект evaluator, который будет отвечать за метрику качества при обучении. Для этого используйте класс BinaryClassificationEvaluator со следующими параметрами: rawPredictionCol — колонка с предсказаниями, labelCol — колонка с таргетом.\n",
        "\n",
        "У вас, возможно, возник вопрос, какую метрику качества берёт по умолчанию BinaryClassificationEvaluator. По умолчанию BinaryClassificationEvaluator будет рассчитывать areaUnderROC. Это метрика оценки площади под кривой ROC (Receiver Operating Characteristic), которая служит графической интерпретацией производительности модели. Эта метрика качества находится в пределах от 0 до 1. Чем выше метрика, тем более качественные предсказания делает модель."
      ],
      "metadata": {
        "id": "zg0lwkdoJjaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(\n",
        "    rawPredictionCol=\"prediction\",  # Колонка с сырыми предсказаниями\n",
        "    labelCol=\"Churn_index\"  # Колонка с целевой переменной\n",
        ")"
      ],
      "metadata": {
        "id": "RrGPelUqMeoz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Создайте объект CrossValidator, в качестве параметров укажите уже созданные вами модель, сетку гиперпараметров и evaluator."
      ],
      "metadata": {
        "id": "7urf-OeRMTdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator\n",
        "\n",
        "crossval = CrossValidator(\n",
        "    estimator=logistic_regression,  # Модель для настройки\n",
        "    estimatorParamMaps=grid,  # Сетка гиперпараметров\n",
        "    evaluator=evaluator,  # Оцениватель качества\n",
        "    numFolds=5  # Количество фолдов для кросс-валидации\n",
        ")"
      ],
      "metadata": {
        "id": "CtmsG_rxSOOr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Запустите обучение модели на тренировочной выборке. Сохраните обученную модель в новую переменную."
      ],
      "metadata": {
        "id": "Jmpv70TjZByl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cv_model = crossval.fit(train_data)"
      ],
      "metadata": {
        "id": "uUxWevjEYOvX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. Выбор лучшей модели"
      ],
      "metadata": {
        "id": "WaIi8In5Zykn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Выберите лучшую модель, сохраните её в отдельную переменную, отобразите её параметры.\n",
        "\n",
        "Вывод параметров модели в PySpark можно сделать, используя метод extractParamMap()."
      ],
      "metadata": {
        "id": "29eo5S_KZL4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = cv_model.bestModel\n",
        "\n",
        "# Вывод параметров лучшей модели\n",
        "best_model_params = best_model.extractParamMap()\n",
        "\n",
        "print(\"Параметры лучшей модели:\")\n",
        "for param, value in best_model_params.items():\n",
        "    print(f\"{param.name}: {value}\")"
      ],
      "metadata": {
        "id": "kJK-IrWLZbL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6d6e7e-fcea-43a5-a229-91885ccb426b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Параметры лучшей модели:\n",
            "aggregationDepth: 2\n",
            "elasticNetParam: 0.01\n",
            "family: auto\n",
            "featuresCol: features\n",
            "fitIntercept: True\n",
            "labelCol: Churn_index\n",
            "maxBlockSizeInMB: 0.0\n",
            "maxIter: 100\n",
            "predictionCol: prediction\n",
            "probabilityCol: probability\n",
            "rawPredictionCol: rawPrediction\n",
            "regParam: 0.5\n",
            "standardization: True\n",
            "threshold: 0.5\n",
            "tol: 1e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Запустите лучшую модель в режиме предсказания на тестовой выборке. Сохраните предсказания в отдельную переменную. Выведите первые несколько строк датафрейма с предсказаниями на экран.\n",
        "\n",
        "Запуск модели в режиме предсказания выполняется при помощи метода .transform(<тестовая выборка>)."
      ],
      "metadata": {
        "id": "1BIe8gqugBds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = best_model.transform(test_data)\n",
        "predictions.show(5)"
      ],
      "metadata": {
        "id": "_K1IrbNzd1FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f6b528-6675-4107-f3b7-97a097e33b83"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+--------------------+--------------------+----------+\n",
            "|            features|Churn_index|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----------+--------------------+--------------------+----------+\n",
            "|(31,[0,1,2,3,4,5,...|        0.0|[1.72182691059702...|[0.84836400432977...|       0.0|\n",
            "|(31,[0,1,2,3,4,5,...|        0.0|[0.36664048122123...|[0.59064695151695...|       0.0|\n",
            "|(31,[0,1,2,3,4,5,...|        1.0|[0.64510081442918...|[0.65590559472130...|       0.0|\n",
            "|(31,[0,1,2,3,4,5,...|        1.0|[0.27992725669108...|[0.56952838985769...|       0.0|\n",
            "|(31,[0,1,2,3,4,5,...|        0.0|[0.27957057367240...|[0.56944094121123...|       0.0|\n",
            "+--------------------+-----------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Получите метрику качества модели. Для этого примените к объекту evaluator метод .evaluate(<ваш датафрейм с предсказаниями>).\n",
        "\n"
      ],
      "metadata": {
        "id": "gC41fZbahGCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Метрика качества модели (Area Under ROC): {metric}\")"
      ],
      "metadata": {
        "id": "CBzDaleQhejy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "955c7c9b-26d9-4415-97b8-8779bdb63408"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метрика качества модели (Area Under ROC): 0.5743481949187124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. Обратная связь\n",
        "Вы ознакомились с возможностями двух мощных библиотек: PySpark SQL для предобработки данных и PySpark ML для машинного обучения."
      ],
      "metadata": {
        "id": "nieC-XnAl-4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поделитесь впечатлениями от работы с новыми библиотеками. В чём они более удобны, чем уже знакомые вам Pandas и Sklearn, а в чём нет."
      ],
      "metadata": {
        "id": "axLO-xV3pJx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преимущества PySpark SQL и PySpark ML\n",
        "\n",
        "Масштабируемость:\n",
        "\n",
        "- Один из самых больших плюсов PySpark — это её способность обрабатывать огромные объемы данных. С PySpark можно работать с распределёнными вычислениями, что позволяет эффективно обрабатывать данные, которые не помещаются в память одного компьютера.\n",
        "\n",
        "- Pandas: Преимущественно используется для обработки данных, которые умещаются в память одного компьютера. Для очень больших данных Pandas может столкнуться с проблемами памяти и производительности.\n",
        "\n",
        "Распределенные вычисления:\n",
        "\n",
        "- PySpark: Использует возможности кластерных вычислений, позволяя выполнять операции параллельно на нескольких узлах. Это делает его идеальным для работы с большими и распределёнными данными.\n",
        "\n",
        "- Pandas: Работает на одном узле, что ограничивает его возможности при обработке больших данных.\n",
        "\n",
        "Интеграция с Big Data технологиями:\n",
        "\n",
        "- PySpark: Легко интегрируется с другими инструментами в экосистеме Hadoop и Spark, что позволяет использовать данные из различных источников и форматов (HDFS, S3 и др.).\n",
        "\n",
        "- Pandas: Взаимодействует с данными в основном через файловые системы или базы данных, интеграция с Big Data решениями менее прямолинейна.\n",
        "\n",
        "Пайплайны машинного обучения:\n",
        "\n",
        "- PySpark ML: Поддерживает создание и настройку сложных пайплайнов машинного обучения, а также использование Grid Search и Cross Validation для выбора гиперпараметров.\n",
        "\n",
        "- Scikit-Learn: Также поддерживает создание пайплайнов и поиск гиперпараметров, но для работы с очень большими данными может потребоваться дополнительное масштабирование или разделение задач.\n",
        "\n",
        "Недостатки и сложности PySpark SQL и PySpark ML\n",
        "\n",
        "Сложность в освоении:\n",
        "\n",
        "- PySpark: Для новичков в Spark экосистеме может быть сложным в освоении из-за большого количества настроек и концепций (RDD, DataFrame, Spark SQL и т.д.).\n",
        "\n",
        "- Pandas: Более интуитивно понятен и прост в использовании для обработки данных на уровне одного компьютера.\n",
        "\n",
        "Ограниченная поддержка некоторых ML моделей:\n",
        "\n",
        "- PySpark ML: Несмотря на то что PySpark ML поддерживает многие популярные модели машинного обучения, в некоторых случаях вам может не хватать более сложных алгоритмов и настроек, которые предоставляют библиотеки такие как Scikit-Learn или XGBoost.\n",
        "\n",
        "- Scikit-Learn: Обладает большим числом встроенных алгоритмов и гибких настроек для машинного обучения.\n",
        "\n",
        "Ресурсы и инфраструктура:\n",
        "\n",
        "- PySpark: Для запуска и работы с PySpark требуется наличие кластера Spark, что может быть сложно и затратно в настройке.\n",
        "\n",
        "- Pandas: Может быть запущен на любом компьютере без необходимости в специальной инфраструктуре."
      ],
      "metadata": {
        "id": "4sv3PfnLr7lc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Как отправить работу на проверку\n",
        "\n",
        "Загрузите файл с заданиями, откройте его через Jupyter Notebook в Google Colab. Скачайте файл с датасетом и загрузите его в Colab. Выполните задачи, сохраните изменения: воспользуйтесь опцией Save and Checkpoint из вкладки меню File или кнопкой Save and Checkpoint на панели инструментов. Отправьте через форму ниже итоговый файл Jupyter Notebook (.ipynb) или ссылку на него."
      ],
      "metadata": {
        "id": "V9TYdK5gl9P4"
      }
    }
  ]
}